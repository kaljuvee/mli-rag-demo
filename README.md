# MLI RAG Demo - AI-Powered Property Portfolio Analysis

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/streamlit-1.32+-red.svg)](https://streamlit.io/)
[![OpenAI](https://img.shields.io/badge/openai-gpt--4o--mini-green.svg)](https://openai.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive **Retrieval-Augmented Generation (RAG)** demonstration application for real estate portfolio analysis, featuring advanced AI-powered querying, property similarity analysis, and intelligent data insights. Built for the MLI (Machine Learning Infrastructure) assessment, this application showcases modern AI engineering practices with production-ready architecture.

## üèóÔ∏è Architecture Overview

The MLI RAG Demo implements a sophisticated multi-layered architecture combining:

- **ü§ñ AI-Powered Text-to-SQL**: Natural language queries converted to SQL using GPT-4o-mini
- **üîç Vector-Based RAG Analysis**: Property similarity search using OpenAI embeddings and FAISS
- **üìä Interactive Web Interface**: Multi-page Streamlit application with real-time processing
- **üóÑÔ∏è Robust Data Pipeline**: Automated Excel processing with SQLite storage
- **üß™ Comprehensive Testing**: Unit tests with JSON result validation
- **üöÄ Production-Ready Deployment**: FastAPI backend with RESTful endpoints

## üìÅ Project Directory Structure

```
mli-rag-demo/
‚îú‚îÄ‚îÄ üìÅ api/                          # FastAPI Backend Services
‚îÇ   ‚îî‚îÄ‚îÄ main.py                      # RESTful API endpoints
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                         # Raw Data Files
‚îÇ   ‚îú‚îÄ‚îÄ CurrentPortfolio.xlsx        # 1,250 current properties
‚îÇ   ‚îî‚îÄ‚îÄ MarketedWarehouses.xlsx      # 5 marketed properties
‚îÇ
‚îú‚îÄ‚îÄ üìÅ db/                           # Database Storage
‚îÇ   ‚îî‚îÄ‚îÄ mli.db                       # SQLite database (auto-generated)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ pages/                        # Streamlit Multi-Page Application
‚îÇ   ‚îú‚îÄ‚îÄ 1_Preprocess.py              # Data loading and preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ 2_Text-to-SQL.py             # Natural language SQL queries
‚îÇ   ‚îú‚îÄ‚îÄ 3_RAG_Analysis.py            # Vector-based property analysis
‚îÇ   ‚îî‚îÄ‚îÄ 4_Simple_Query.py            # Basic database queries (testing)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ test-data/                    # Unit Test Results (JSON)
‚îÇ   ‚îú‚îÄ‚îÄ README.md                    # Test data documentation
‚îÇ   ‚îú‚îÄ‚îÄ FINAL_TEST_RESULTS.md        # Comprehensive test summary
‚îÇ   ‚îú‚îÄ‚îÄ TEST_RESULTS_SUMMARY.md      # Detailed test analysis
‚îÇ   ‚îú‚îÄ‚îÄ query_1_similar_properties.json      # Similarity analysis results
‚îÇ   ‚îú‚îÄ‚îÄ query_2_correlation_score.json       # Correlation analysis results
‚îÇ   ‚îú‚îÄ‚îÄ query_3_closest_properties.json      # Geographic proximity results
‚îÇ   ‚îú‚îÄ‚îÄ simple_queries.json                  # Basic functionality tests
‚îÇ   ‚îú‚îÄ‚îÄ sql_generation_results.json          # SQL validation tests
‚îÇ   ‚îú‚îÄ‚îÄ rag_similarity_search.json           # RAG similarity tests
‚îÇ   ‚îú‚îÄ‚îÄ rag_cluster_analysis.json            # RAG clustering tests
‚îÇ   ‚îú‚îÄ‚îÄ rag_homogeneity_analysis.json        # RAG homogeneity tests
‚îÇ   ‚îî‚îÄ‚îÄ rag_comprehensive_analysis.json      # Complete RAG analysis
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                        # Unit Test Suite
‚îÇ   ‚îú‚îÄ‚îÄ test_sql_chat.py             # SQL chat functionality tests
‚îÇ   ‚îú‚îÄ‚îÄ test_rag_chat.py             # RAG chat functionality tests
‚îÇ   ‚îú‚îÄ‚îÄ test_xls_converter.py        # Data processing tests
‚îÇ   ‚îî‚îÄ‚îÄ test_db_util.py              # Database utility tests
‚îÇ
‚îú‚îÄ‚îÄ üìÅ utils/                        # Core Utility Modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ ai_util.py                   # OpenAI client management
‚îÇ   ‚îú‚îÄ‚îÄ db_util.py                   # SQLite database operations
‚îÇ   ‚îú‚îÄ‚îÄ rag_util.py                  # Vector embeddings and FAISS
‚îÇ   ‚îú‚îÄ‚îÄ xls_converter.py             # Excel data processing
‚îÇ   ‚îú‚îÄ‚îÄ sql_chat.py                  # LangChain SQL agent
‚îÇ   ‚îú‚îÄ‚îÄ simple_sql_chat.py           # Simplified SQL chat
‚îÇ   ‚îú‚îÄ‚îÄ mock_sql_chat.py             # Mock SQL chat (testing)
‚îÇ   ‚îî‚îÄ‚îÄ rag_chat.py                  # RAG-based property analysis
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Home.py                       # Main Streamlit application entry
‚îú‚îÄ‚îÄ üìÑ requirements.txt              # Python dependencies (version-free)
‚îú‚îÄ‚îÄ üìÑ .env.sample                   # Environment variables template
‚îú‚îÄ‚îÄ üìÑ .env                          # Environment configuration (local)
‚îú‚îÄ‚îÄ üìÑ .gitignore                    # Git ignore patterns
‚îú‚îÄ‚îÄ üìÑ PROJECT_SUMMARY.md            # Detailed project documentation
‚îî‚îÄ‚îÄ üìÑ README.md                     # This comprehensive guide
```

## üöÄ Quick Start Guide

### Prerequisites

- **Python 3.11+** (recommended)
- **OpenAI API Key** (for GPT-4o-mini and embeddings)
- **Git** (for cloning the repository)

### 1. Clone and Setup

```bash
# Clone the repository
git clone https://github.com/kaljuvee/mli-rag-demo.git
cd mli-rag-demo

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Environment Configuration

```bash
# Copy environment template
cp .env.sample .env

# Edit .env file with your OpenAI API key
echo "OPENAI_API_KEY=your_openai_api_key_here" > .env
```

### 3. Launch Application

```bash
# Start Streamlit application
streamlit run Home.py

# Alternative: Start FastAPI backend
uvicorn api.main:app --reload --port 8000
```

### 4. Access the Application

- **Streamlit Web Interface**: http://localhost:8501
- **FastAPI Documentation**: http://localhost:8000/docs
- **API Health Check**: http://localhost:8000/health

## üéØ Core Features

### 1. üìä Data Preprocessing Pipeline

**Location**: `pages/1_Preprocess.py`

- **Automated Excel Processing**: Loads and combines CurrentPortfolio.xlsx (1,250 properties) and MarketedWarehouses.xlsx (5 properties)
- **Data Cleaning & Validation**: Handles missing values, standardizes formats, validates data integrity
- **SQLite Database Creation**: Generates optimized database schema with proper indexing
- **Real-time Progress Feedback**: Visual confirmation of data loading with preview tables

**Key Capabilities**:
- Intelligent data type inference and conversion
- Missing value imputation strategies
- Duplicate detection and handling
- Coordinate validation and geocoding support

### 2. ü§ñ AI-Powered Text-to-SQL

**Location**: `pages/2_Text-to-SQL.py`

Transform natural language questions into executable SQL queries using advanced language models.

**Example Queries**:
```
"Find the 10 most similar properties to the newly marketed property"
‚Üí Complex similarity analysis with size and age metrics

"Provide a correlation score for homogeneity of marketed properties"
‚Üí Multi-dimensional correlation analysis across physical, location, and age characteristics

"Find closest properties excluding those >10 miles from major cities"
‚Üí Geographic proximity analysis with Haversine distance calculations
```

**Technical Implementation**:
- **LangChain SQL Agent**: Sophisticated query planning and execution
- **Schema-Aware Generation**: Understands database structure and relationships
- **Error Handling & Validation**: Robust query validation and error recovery
- **Performance Optimization**: Query optimization and result caching

### 3. üîç RAG-Based Property Analysis

**Location**: `pages/3_RAG_Analysis.py`

Advanced vector-based analysis using Retrieval-Augmented Generation for property insights.

**Core Capabilities**:
- **Property Similarity Search**: Find similar properties using multi-dimensional embeddings
- **Portfolio Clustering**: Identify distinct property groups and market segments
- **Homogeneity Analysis**: Measure portfolio consistency and diversification
- **Contextual AI Responses**: Generate insights with property-specific context

**Vector Analysis Features**:
- **OpenAI Embeddings**: High-dimensional property representations
- **FAISS Vector Search**: Efficient similarity search and clustering
- **Cosine Similarity Metrics**: Precise similarity scoring
- **Dynamic Context Generation**: Adaptive context for AI responses

### 4. üóÑÔ∏è Database Management

**Location**: `utils/db_util.py`

Robust SQLite database operations with optimized performance.

**Database Schema**:
```sql
CREATE TABLE properties (
    property_id REAL,
    industrial_estate_name TEXT,
    unit_name TEXT,
    region TEXT,
    latitude REAL,
    longitude REAL,
    car_parking_spaces INTEGER,
    size_sqm REAL,
    build_year REAL,
    yard_depth_m REAL,
    min_eaves_m REAL,
    max_eaves_m REAL,
    doors INTEGER,
    epc_rating TEXT,
    is_marketed INTEGER
);
```

**Performance Features**:
- Optimized indexing for common queries
- Connection pooling and management
- Transaction safety and rollback support
- Query result caching

## üß™ Testing Framework

### Comprehensive Unit Testing

The project includes extensive unit tests with JSON result validation:

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test suites
python tests/test_sql_chat.py      # SQL functionality
python tests/test_rag_chat.py      # RAG functionality
python tests/test_db_util.py       # Database operations
python tests/test_xls_converter.py # Data processing
```

### Test Coverage

- **SQL Chat Tests**: 6 test cases covering query generation and execution
- **RAG Analysis Tests**: 8 test cases covering vector operations and similarity search
- **Database Tests**: 4 test cases covering CRUD operations and schema validation
- **Data Processing Tests**: 3 test cases covering Excel parsing and transformation

### JSON Test Results

All test results are saved as structured JSON files in `test-data/` for:
- **Result Validation**: Verify query outputs against expected results
- **Performance Monitoring**: Track query execution times and accuracy
- **Regression Testing**: Ensure consistent behavior across updates
- **Documentation**: Provide examples of expected system behavior

## üîß API Documentation

### FastAPI Endpoints

**Location**: `api/main.py`

```python
# Health Check
GET /health
‚Üí {"status": "healthy", "timestamp": "2025-09-18T10:30:00Z"}

# Property Search
POST /properties/search
Body: {"query": "Find properties in London", "limit": 10}
‚Üí {"results": [...], "count": 10, "execution_time": 0.15}

# Similarity Analysis
POST /properties/similar
Body: {"property_id": 123, "top_k": 5}
‚Üí {"similar_properties": [...], "similarity_scores": [...]}

# RAG Query
POST /rag/query
Body: {"question": "What is the portfolio homogeneity?"}
‚Üí {"answer": "...", "context": [...], "confidence": 0.95}
```

## üìà Performance Metrics

### Query Performance

- **Text-to-SQL Generation**: ~2-3 seconds per query
- **Vector Similarity Search**: ~0.1-0.5 seconds for 1,255 properties
- **Database Queries**: ~0.01-0.1 seconds for most operations
- **RAG Context Generation**: ~1-2 seconds including embeddings

### Scalability

- **Database**: Tested with 1,255 properties, scales to 100K+ with indexing
- **Vector Search**: FAISS enables sub-second search on millions of vectors
- **Concurrent Users**: Streamlit supports 10+ concurrent users
- **Memory Usage**: ~200MB baseline, ~500MB with full vector cache

## üõ†Ô∏è Development Guide

### Adding New Features

1. **New Query Types**: Extend `utils/sql_chat.py` with additional query patterns
2. **Vector Analysis**: Add new similarity metrics in `utils/rag_util.py`
3. **UI Components**: Create new pages in `pages/` directory
4. **API Endpoints**: Extend `api/main.py` with new routes

### Code Quality Standards

- **Type Hints**: All functions include comprehensive type annotations
- **Documentation**: Docstrings for all classes and methods
- **Error Handling**: Robust exception handling with user-friendly messages
- **Testing**: Unit tests required for all new functionality

### Environment Variables

```bash
# Required
OPENAI_API_KEY=sk-...                    # OpenAI API key for GPT and embeddings

# Optional
DATABASE_URL=sqlite:///db/mli.db         # Database connection string
LOG_LEVEL=INFO                           # Logging verbosity
CACHE_TTL=3600                           # Cache time-to-live in seconds
MAX_QUERY_TIME=30                        # Maximum query execution time
```

## üöÄ Deployment Options

### Local Development

```bash
# Development server with hot reload
streamlit run Home.py --server.runOnSave true
```

### Production Deployment

#### Streamlit Cloud
1. Connect GitHub repository to Streamlit Cloud
2. Configure environment variables in Streamlit dashboard
3. Deploy with automatic SSL and CDN

#### Docker Deployment
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8501
CMD ["streamlit", "run", "Home.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

#### Cloud Platforms
- **AWS**: Deploy on EC2 with Application Load Balancer
- **Google Cloud**: Use Cloud Run for serverless deployment
- **Azure**: Deploy on Container Instances or App Service

## üìä Data Sources

### Current Portfolio (1,250 properties)
- **Source**: CurrentPortfolio.xlsx
- **Columns**: Property ID, Estate Name, Unit, Region, Coordinates, Size, Build Year, Physical Characteristics
- **Coverage**: UK-wide industrial properties across multiple regions

### Marketed Warehouses (5 properties)
- **Source**: MarketedWarehouses.xlsx
- **Properties**: Cherry Lane, Tech Hub, Spitfire Park, Stable Lane, Chancery Depot
- **Purpose**: Target properties for similarity analysis and portfolio comparison

## ü§ù Contributing

### Development Workflow

1. **Fork the repository** and create a feature branch
2. **Implement changes** following code quality standards
3. **Add unit tests** for new functionality
4. **Update documentation** including README and docstrings
5. **Submit pull request** with detailed description

### Issue Reporting

Please use GitHub Issues for:
- üêõ Bug reports with reproduction steps
- üí° Feature requests with use case descriptions
- üìö Documentation improvements
- ‚ùì Questions about implementation

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **OpenAI** for GPT-4o-mini and embedding models
- **LangChain** for SQL agent framework
- **Streamlit** for rapid web application development
- **FAISS** for efficient vector similarity search
- **MLI Assessment Team** for the comprehensive evaluation framework

## üìû Support

For questions, issues, or contributions:

- **GitHub Issues**: [Create an issue](https://github.com/kaljuvee/mli-rag-demo/issues)
- **Documentation**: See `PROJECT_SUMMARY.md` for detailed technical documentation
- **Test Results**: Check `test-data/` directory for validation examples

---

**Built with ‚ù§Ô∏è for the MLI Assessment - Demonstrating Production-Ready AI Engineering**
